{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Forecasting Challenge - Data Preprocessing and EDA\n",
      "================================================================================\n",
      "\n",
      "1. Loading and Examining the Dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "Data Overview:\n",
      "Dataset Shape: (311, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>rain_or_not</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>23.745401</td>\n",
       "      <td>46.140905</td>\n",
       "      <td>7.845981</td>\n",
       "      <td>Rain</td>\n",
       "      <td>20.851051</td>\n",
       "      <td>992.965681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>30.030503</td>\n",
       "      <td>59.876587</td>\n",
       "      <td>5.382457</td>\n",
       "      <td>Rain</td>\n",
       "      <td>93.059521</td>\n",
       "      <td>1037.273025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>28.365224</td>\n",
       "      <td>51.464618</td>\n",
       "      <td>13.158008</td>\n",
       "      <td>Rain</td>\n",
       "      <td>11.636640</td>\n",
       "      <td>1034.193357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>27.550929</td>\n",
       "      <td>53.103799</td>\n",
       "      <td>5.886677</td>\n",
       "      <td>Rain</td>\n",
       "      <td>81.744971</td>\n",
       "      <td>968.610142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>23.639303</td>\n",
       "      <td>57.826186</td>\n",
       "      <td>12.248992</td>\n",
       "      <td>Rain</td>\n",
       "      <td>38.062329</td>\n",
       "      <td>1030.264331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  avg_temperature   humidity  avg_wind_speed rain_or_not  \\\n",
       "0  2023-01-01        23.745401  46.140905        7.845981        Rain   \n",
       "1  2023-01-02        30.030503  59.876587        5.382457        Rain   \n",
       "2  2023-01-03        28.365224  51.464618       13.158008        Rain   \n",
       "3  2023-01-04        27.550929  53.103799        5.886677        Rain   \n",
       "4  2023-01-05        23.639303  57.826186       12.248992        Rain   \n",
       "\n",
       "   cloud_cover     pressure  \n",
       "0    20.851051   992.965681  \n",
       "1    93.059521  1037.273025  \n",
       "2    11.636640  1034.193357  \n",
       "3    81.744971   968.610142  \n",
       "4    38.062329  1030.264331  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 311 entries, 0 to 310\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   date             311 non-null    object \n",
      " 1   avg_temperature  296 non-null    float64\n",
      " 2   humidity         296 non-null    float64\n",
      " 3   avg_wind_speed   296 non-null    float64\n",
      " 4   rain_or_not      311 non-null    object \n",
      " 5   cloud_cover      296 non-null    float64\n",
      " 6   pressure         311 non-null    float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 17.1+ KB\n",
      "\n",
      "Summary Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>296.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>311.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.983840</td>\n",
       "      <td>55.041385</td>\n",
       "      <td>7.556636</td>\n",
       "      <td>49.834827</td>\n",
       "      <td>1001.059119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.802475</td>\n",
       "      <td>19.220133</td>\n",
       "      <td>5.344683</td>\n",
       "      <td>29.009459</td>\n",
       "      <td>28.835595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.069480</td>\n",
       "      <td>0.321826</td>\n",
       "      <td>951.240404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.265692</td>\n",
       "      <td>34.280826</td>\n",
       "      <td>3.550354</td>\n",
       "      <td>24.530951</td>\n",
       "      <td>975.757545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.177958</td>\n",
       "      <td>56.759806</td>\n",
       "      <td>7.326421</td>\n",
       "      <td>50.725120</td>\n",
       "      <td>1001.938586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32.204599</td>\n",
       "      <td>72.189837</td>\n",
       "      <td>11.050627</td>\n",
       "      <td>76.046506</td>\n",
       "      <td>1026.578884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>56.636041</td>\n",
       "      <td>99.834751</td>\n",
       "      <td>1049.543752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_temperature    humidity  avg_wind_speed  cloud_cover     pressure\n",
       "count       296.000000  296.000000      296.000000   296.000000   311.000000\n",
       "mean         25.983840   55.041385        7.556636    49.834827  1001.059119\n",
       "std           6.802475   19.220133        5.344683    29.009459    28.835595\n",
       "min          15.000000   30.000000        0.069480     0.321826   951.240404\n",
       "25%          20.265692   34.280826        3.550354    24.530951   975.757545\n",
       "50%          27.177958   56.759806        7.326421    50.725120  1001.938586\n",
       "75%          32.204599   72.189837       11.050627    76.046506  1026.578884\n",
       "max          35.000000   90.000000       56.636041    99.834751  1049.543752"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_temperature</th>\n",
       "      <td>15</td>\n",
       "      <td>4.823151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>15</td>\n",
       "      <td>4.823151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <td>15</td>\n",
       "      <td>4.823151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain_or_not</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud_cover</th>\n",
       "      <td>15</td>\n",
       "      <td>4.823151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Missing Values  Percentage\n",
       "date                          0    0.000000\n",
       "avg_temperature              15    4.823151\n",
       "humidity                     15    4.823151\n",
       "avg_wind_speed               15    4.823151\n",
       "rain_or_not                   0    0.000000\n",
       "cloud_cover                  15    4.823151\n",
       "pressure                      0    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Data Preprocessing\n",
      "--------------------------------------------------\n",
      "\n",
      "Converting date column to datetime...\n",
      "\n",
      "Converting target variable to binary...\n",
      "Unique values in rain_or_not column: ['Rain' 'No Rain']\n",
      "\n",
      "Rain distribution after conversion: {1: 198, 0: 113}\n",
      "Percentage of rainy days: 63.67%\n",
      "\n",
      "Handling missing values...\n",
      "Columns with missing values: ['avg_temperature', 'humidity', 'avg_wind_speed', 'cloud_cover']\n",
      "Filled missing values in 'avg_temperature' with median: 27.177958126582883\n",
      "Filled missing values in 'humidity' with median: 56.75980567828731\n",
      "Filled missing values in 'avg_wind_speed' with median: 7.326421214194906\n",
      "Filled missing values in 'cloud_cover' with median: 50.7251204878262\n",
      "\n",
      "Remaining missing values after imputation: 0\n",
      "\n",
      "Extracting features from date...\n",
      "\n",
      "Data after feature engineering:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  month  day_of_week  day_of_year  season\n",
       "0 2023-01-01      1            6            1  Winter\n",
       "1 2023-01-02      1            0            2  Winter\n",
       "2 2023-01-03      1            1            3  Winter\n",
       "3 2023-01-04      1            2            4  Winter\n",
       "4 2023-01-05      1            3            5  Winter"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for outliers in numeric features...\n",
      "\n",
      "Normalizing numerical features...\n",
      "\n",
      "Data after normalization:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.110000e+02</td>\n",
       "      <td>3.110000e+02</td>\n",
       "      <td>3.110000e+02</td>\n",
       "      <td>3.110000e+02</td>\n",
       "      <td>3.110000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.028116e-16</td>\n",
       "      <td>4.569407e-16</td>\n",
       "      <td>7.425286e-17</td>\n",
       "      <td>-2.855879e-17</td>\n",
       "      <td>8.674733e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001612e+00</td>\n",
       "      <td>1.001612e+00</td>\n",
       "      <td>1.001612e+00</td>\n",
       "      <td>1.001612e+00</td>\n",
       "      <td>1.001612e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.665345e+00</td>\n",
       "      <td>-1.341906e+00</td>\n",
       "      <td>-1.436151e+00</td>\n",
       "      <td>-1.753943e+00</td>\n",
       "      <td>-1.730466e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.367950e-01</td>\n",
       "      <td>-1.038202e+00</td>\n",
       "      <td>-7.364830e-01</td>\n",
       "      <td>-8.466853e-01</td>\n",
       "      <td>-8.788565e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.714184e-01</td>\n",
       "      <td>8.735538e-02</td>\n",
       "      <td>-4.209132e-02</td>\n",
       "      <td>2.999052e-02</td>\n",
       "      <td>3.054851e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.773980e-01</td>\n",
       "      <td>9.001727e-01</td>\n",
       "      <td>6.438495e-01</td>\n",
       "      <td>8.595001e-01</td>\n",
       "      <td>8.864354e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.351192e+00</td>\n",
       "      <td>1.862740e+00</td>\n",
       "      <td>9.430295e+00</td>\n",
       "      <td>1.768137e+00</td>\n",
       "      <td>1.684126e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_temperature      humidity  avg_wind_speed   cloud_cover  \\\n",
       "count     3.110000e+02  3.110000e+02    3.110000e+02  3.110000e+02   \n",
       "mean      1.028116e-16  4.569407e-16    7.425286e-17 -2.855879e-17   \n",
       "std       1.001612e+00  1.001612e+00    1.001612e+00  1.001612e+00   \n",
       "min      -1.665345e+00 -1.341906e+00   -1.436151e+00 -1.753943e+00   \n",
       "25%      -8.367950e-01 -1.038202e+00   -7.364830e-01 -8.466853e-01   \n",
       "50%       1.714184e-01  8.735538e-02   -4.209132e-02  2.999052e-02   \n",
       "75%       8.773980e-01  9.001727e-01    6.438495e-01  8.595001e-01   \n",
       "max       1.351192e+00  1.862740e+00    9.430295e+00  1.768137e+00   \n",
       "\n",
       "           pressure  \n",
       "count  3.110000e+02  \n",
       "mean   8.674733e-16  \n",
       "std    1.001612e+00  \n",
       "min   -1.730466e+00  \n",
       "25%   -8.788565e-01  \n",
       "50%    3.054851e-02  \n",
       "75%    8.864354e-01  \n",
       "max    1.684126e+00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Exploratory Data Analysis\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing the distribution of the target variable...\n",
      "\n",
      "Analyzing the distribution of numeric features...\n",
      "\n",
      "Analyzing feature correlations...\n",
      "\n",
      "Correlation of features with rain_or_not_binary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rain_or_not_binary    1.000000\n",
       "humidity              0.321515\n",
       "avg_temperature       0.294066\n",
       "avg_wind_speed        0.125911\n",
       "pressure              0.090059\n",
       "cloud_cover          -0.034236\n",
       "Name: rain_or_not_binary, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing relationships between features and rain occurrence...\n",
      "\n",
      "Analyzing seasonal patterns in rainfall...\n",
      "\n",
      "Analyzing relationships between features...\n",
      "\n",
      "Time series analysis of weather variables...\n",
      "\n",
      "Analyzing rain probability by feature ranges...\n",
      "\n",
      "4. Summary of EDA Findings\n",
      "--------------------------------------------------\n",
      "\n",
      "Key findings from exploratory data analysis:\n",
      "- Target Distribution: 63.67% of days have rain\n",
      "- Most correlated features with rain:\n",
      "  * humidity: 0.3215\n",
      "  * avg_temperature: 0.2941\n",
      "  * avg_wind_speed: 0.1259\n",
      "\n",
      "Preprocessing and EDA completed successfully!\n",
      "All visualizations have been saved as PNG files.\n",
      "\n",
      "Processed data saved to 'weather_data_processed.csv'\n",
      "\n",
      "5. Preparing Data for Modeling\n",
      "--------------------------------------------------\n",
      "Feature matrix shape: (311, 9)\n",
      "Target vector shape: (311,)\n",
      "\n",
      "Features to be used in modeling:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['avg_temperature',\n",
       " 'humidity',\n",
       " 'avg_wind_speed',\n",
       " 'cloud_cover',\n",
       " 'pressure',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'day_of_year',\n",
       " 'season']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data is now ready for model training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Weather Forecasting Challenge - Data Preprocessing and EDA\n",
    "# Intellihack 5 Hackathon\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Weather Forecasting Challenge - Data Preprocessing and EDA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Data Loading\n",
    "print(\"\\n1. Loading and Examining the Dataset\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('weather_data.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"\\nData Overview:\")\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nData Information:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nChecking for missing values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "display(missing_df)\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "print(\"\\n2. Data Preprocessing\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Make a copy of the dataframe to preserve the original\n",
    "df_processed = df.copy()\n",
    "\n",
    "# 2.1 Convert the date column to datetime type\n",
    "print(\"\\nConverting date column to datetime...\")\n",
    "df_processed['date'] = pd.to_datetime(df_processed['date'])\n",
    "\n",
    "# 2.2 Handle the target variable - convert 'Rain'/'No Rain' text to binary\n",
    "print(\"\\nConverting target variable to binary...\")\n",
    "# Check unique values in the target column\n",
    "print(f\"Unique values in rain_or_not column: {df_processed['rain_or_not'].unique()}\")\n",
    "\n",
    "# Convert to binary (1 = Rain, 0 = No Rain)\n",
    "df_processed['rain_or_not_binary'] = df_processed['rain_or_not'].apply(lambda x: 1 if str(x).lower() == 'rain' else 0)\n",
    "\n",
    "# Display the conversion\n",
    "rain_counts = df_processed['rain_or_not_binary'].value_counts()\n",
    "print(f\"\\nRain distribution after conversion: {rain_counts.to_dict()}\")\n",
    "print(f\"Percentage of rainy days: {rain_counts[1] / len(df_processed) * 100:.2f}%\")\n",
    "\n",
    "# 2.3 Handle missing values\n",
    "print(\"\\nHandling missing values...\")\n",
    "\n",
    "# Check for columns with missing values\n",
    "columns_with_missing = df_processed.columns[df_processed.isnull().any()].tolist()\n",
    "print(f\"Columns with missing values: {columns_with_missing}\")\n",
    "\n",
    "# For numeric columns, impute missing values with median\n",
    "for col in columns_with_missing:\n",
    "    if df_processed[col].dtype in ['int64', 'float64']:\n",
    "        median_value = df_processed[col].median()\n",
    "        df_processed[col].fillna(median_value, inplace=True)\n",
    "        print(f\"Filled missing values in '{col}' with median: {median_value}\")\n",
    "\n",
    "# Check if we have any remaining missing values\n",
    "remaining_missing = df_processed.isnull().sum().sum()\n",
    "print(f\"\\nRemaining missing values after imputation: {remaining_missing}\")\n",
    "\n",
    "# 2.4 Feature Engineering from date\n",
    "print(\"\\nExtracting features from date...\")\n",
    "df_processed['month'] = df_processed['date'].dt.month\n",
    "df_processed['day_of_week'] = df_processed['date'].dt.dayofweek\n",
    "df_processed['day_of_year'] = df_processed['date'].dt.dayofyear\n",
    "df_processed['season'] = df_processed['month'].apply(lambda x: \n",
    "                                               'Winter' if x in [12, 1, 2] else\n",
    "                                               'Spring' if x in [3, 4, 5] else\n",
    "                                               'Summer' if x in [6, 7, 8] else 'Fall')\n",
    "\n",
    "print(\"\\nData after feature engineering:\")\n",
    "display(df_processed[['date', 'month', 'day_of_week', 'day_of_year', 'season']].head())\n",
    "\n",
    "# 2.5 Check for outliers\n",
    "print(\"\\nChecking for outliers in numeric features...\")\n",
    "numeric_features = df_processed.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numeric_features = [col for col in numeric_features if col != 'rain_or_not_binary']\n",
    "\n",
    "# Create box plots for numeric features\n",
    "plt.figure(figsize=(14, 10))\n",
    "for i, feature in enumerate(numeric_features[:6], 1):  # Limit to 6 features for visibility\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.boxplot(y=df_processed[feature])\n",
    "    plt.title(f'Box Plot of {feature}')\n",
    "    plt.tight_layout()\n",
    "plt.savefig('outliers_boxplot.png')\n",
    "plt.close()\n",
    "\n",
    "# 2.6 Normalize numerical features\n",
    "print(\"\\nNormalizing numerical features...\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a copy of the features to be normalized\n",
    "features_to_normalize = ['avg_temperature', 'humidity', 'avg_wind_speed', 'cloud_cover', 'pressure']\n",
    "features_to_normalize = [f for f in features_to_normalize if f in df_processed.columns]\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the selected features\n",
    "df_processed[features_to_normalize] = scaler.fit_transform(df_processed[features_to_normalize])\n",
    "\n",
    "print(\"\\nData after normalization:\")\n",
    "display(df_processed[features_to_normalize].describe())\n",
    "\n",
    "# 3. Exploratory Data Analysis (EDA)\n",
    "print(\"\\n3. Exploratory Data Analysis\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 3.1 Distribution of the target variable\n",
    "print(\"\\nAnalyzing the distribution of the target variable...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='rain_or_not_binary', data=df_processed)\n",
    "plt.title('Distribution of Rain vs No Rain Days')\n",
    "plt.xlabel('Rain (1) vs No Rain (0)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['No Rain', 'Rain'])\n",
    "plt.savefig('rain_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# 3.2 Distribution of numeric features\n",
    "print(\"\\nAnalyzing the distribution of numeric features...\")\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, feature in enumerate(features_to_normalize, 1):\n",
    "    plt.subplot(3, 2, i)\n",
    "    sns.histplot(df_processed[feature], kde=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_distributions.png')\n",
    "plt.close()\n",
    "\n",
    "# 3.3 Correlation matrix\n",
    "print(\"\\nAnalyzing feature correlations...\")\n",
    "correlation_matrix = df_processed[features_to_normalize + ['rain_or_not_binary']].corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.savefig('correlation_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Display correlation with target\n",
    "print(\"\\nCorrelation of features with rain_or_not_binary:\")\n",
    "target_correlation = correlation_matrix['rain_or_not_binary'].sort_values(ascending=False)\n",
    "display(target_correlation)\n",
    "\n",
    "# 3.4 Feature relationships with target\n",
    "print(\"\\nAnalyzing relationships between features and rain occurrence...\")\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, feature in enumerate(features_to_normalize, 1):\n",
    "    plt.subplot(3, 2, i)\n",
    "    sns.boxplot(x='rain_or_not_binary', y=feature, data=df_processed)\n",
    "    plt.title(f'{feature} vs Rain')\n",
    "    plt.xlabel('Rain (1) vs No Rain (0)')\n",
    "    plt.xticks([0, 1], ['No Rain', 'Rain'])\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_vs_rain.png')\n",
    "plt.close()\n",
    "\n",
    "# 3.5 Seasonal patterns in rainfall\n",
    "print(\"\\nAnalyzing seasonal patterns in rainfall...\")\n",
    "# Group by month and calculate percentage of rainy days\n",
    "monthly_rain = df_processed.groupby('month')['rain_or_not_binary'].mean() * 100\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_rain.plot(kind='bar', color='skyblue')\n",
    "plt.title('Percentage of Rainy Days by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Percentage of Rainy Days')\n",
    "plt.xticks(range(12), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.savefig('monthly_rain_pattern.png')\n",
    "plt.close()\n",
    "\n",
    "# 3.6 Feature relationships\n",
    "print(\"\\nAnalyzing relationships between features...\")\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.pairplot(df_processed[features_to_normalize + ['rain_or_not_binary']], \n",
    "             hue='rain_or_not_binary', palette={0: 'skyblue', 1: 'salmon'})\n",
    "plt.savefig('feature_relationships.png')\n",
    "plt.close()\n",
    "\n",
    "# 3.7 Time series analysis\n",
    "print(\"\\nTime series analysis of weather variables...\")\n",
    "# Select a subset of features for time series visualization\n",
    "time_series_features = ['avg_temperature', 'humidity', 'avg_wind_speed', 'rain_or_not_binary']\n",
    "time_series_features = [f for f in time_series_features if f in df_processed.columns]\n",
    "\n",
    "# Plot time series for these features\n",
    "fig, axes = plt.subplots(len(time_series_features), 1, figsize=(14, 12), sharex=True)\n",
    "for i, feature in enumerate(time_series_features):\n",
    "    axes[i].plot(df_processed['date'], df_processed[feature], marker='o', linestyle='-', markersize=2)\n",
    "    axes[i].set_title(f'{feature} Over Time')\n",
    "    axes[i].set_ylabel(feature)\n",
    "    if feature == 'rain_or_not_binary':\n",
    "        axes[i].set_yticks([0, 1])\n",
    "        axes[i].set_yticklabels(['No Rain', 'Rain'])\n",
    "plt.tight_layout()\n",
    "plt.savefig('time_series_analysis.png')\n",
    "plt.close()\n",
    "\n",
    "# 3.8 Rain probability by features\n",
    "print(\"\\nAnalyzing rain probability by feature ranges...\")\n",
    "# For each numeric feature, divide into bins and calculate rain probability\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, feature in enumerate(features_to_normalize[:5], 1):  # Limit to 5 features\n",
    "    plt.subplot(3, 2, i)\n",
    "    # Create bins for the feature\n",
    "    df_processed[f'{feature}_bins'] = pd.qcut(df_processed[feature], 10, duplicates='drop')\n",
    "    # Calculate rain probability for each bin\n",
    "    rain_by_feature = df_processed.groupby(f'{feature}_bins')['rain_or_not_binary'].mean() * 100\n",
    "    rain_by_feature.plot(kind='bar')\n",
    "    plt.title(f'Rain Probability by {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Rain Probability (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('rain_probability_by_features.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. Summary of findings\n",
    "print(\"\\n4. Summary of EDA Findings\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nKey findings from exploratory data analysis:\")\n",
    "print(\"- Target Distribution: {}% of days have rain\".format(round(df_processed['rain_or_not_binary'].mean() * 100, 2)))\n",
    "print(\"- Most correlated features with rain:\")\n",
    "for feature, corr in target_correlation.items():\n",
    "    if feature != 'rain_or_not_binary' and abs(corr) > 0.1:\n",
    "        print(f\"  * {feature}: {corr:.4f}\")\n",
    "\n",
    "print(\"\\nPreprocessing and EDA completed successfully!\")\n",
    "print(\"All visualizations have been saved as PNG files.\")\n",
    "\n",
    "# Save the processed dataframe for further analysis\n",
    "df_processed.to_csv('weather_data_processed.csv', index=False)\n",
    "print(\"\\nProcessed data saved to 'weather_data_processed.csv'\")\n",
    "\n",
    "# 5. Prepare data for modeling\n",
    "print(\"\\n5. Preparing Data for Modeling\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Define features and target\n",
    "X = df_processed.drop(['date', 'rain_or_not', 'rain_or_not_binary'], axis=1)\n",
    "# Remove any bin columns created during EDA\n",
    "X = X.loc[:, ~X.columns.str.contains('_bins')]\n",
    "y = df_processed['rain_or_not_binary']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "print(\"\\nFeatures to be used in modeling:\")\n",
    "display(X.columns.tolist())\n",
    "\n",
    "# Ready for model training\n",
    "print(\"\\nData is now ready for model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Forecasting Challenge - Model Training and Evaluation\n",
      "================================================================================\n",
      "\n",
      "1. Loading the processed data\n",
      "--------------------------------------------------\n",
      "Loaded dataset shape: (311, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>rain_or_not</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>pressure</th>\n",
       "      <th>rain_or_not_binary</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>season</th>\n",
       "      <th>avg_temperature_bins</th>\n",
       "      <th>humidity_bins</th>\n",
       "      <th>avg_wind_speed_bins</th>\n",
       "      <th>cloud_cover_bins</th>\n",
       "      <th>pressure_bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-0.346303</td>\n",
       "      <td>-0.479808</td>\n",
       "      <td>0.057716</td>\n",
       "      <td>Rain</td>\n",
       "      <td>-1.027348</td>\n",
       "      <td>-0.281128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>(-0.655, -0.253]</td>\n",
       "      <td>(-0.813, -0.303]</td>\n",
       "      <td>(-0.0421, 0.187]</td>\n",
       "      <td>(-1.049, -0.649]</td>\n",
       "      <td>(-0.727, -0.244]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>0.601659</td>\n",
       "      <td>0.253825</td>\n",
       "      <td>-0.415527</td>\n",
       "      <td>Rain</td>\n",
       "      <td>1.528340</td>\n",
       "      <td>1.257899</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Winter</td>\n",
       "      <td>(0.444, 0.8]</td>\n",
       "      <td>(0.0874, 0.412]</td>\n",
       "      <td>(-0.593, -0.3]</td>\n",
       "      <td>(1.337, 1.768]</td>\n",
       "      <td>(1.071, 1.326]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>0.350490</td>\n",
       "      <td>-0.195465</td>\n",
       "      <td>1.078158</td>\n",
       "      <td>Rain</td>\n",
       "      <td>-1.353475</td>\n",
       "      <td>1.150926</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Winter</td>\n",
       "      <td>(0.171, 0.444]</td>\n",
       "      <td>(-0.303, 0.0874]</td>\n",
       "      <td>(0.838, 1.126]</td>\n",
       "      <td>(-1.418, -1.049]</td>\n",
       "      <td>(1.071, 1.326]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>0.227672</td>\n",
       "      <td>-0.107915</td>\n",
       "      <td>-0.318667</td>\n",
       "      <td>Rain</td>\n",
       "      <td>1.127882</td>\n",
       "      <td>-1.127123</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Winter</td>\n",
       "      <td>(0.171, 0.444]</td>\n",
       "      <td>(-0.303, 0.0874]</td>\n",
       "      <td>(-0.593, -0.3]</td>\n",
       "      <td>(1.013, 1.337]</td>\n",
       "      <td>(-1.412, -1.072]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>-0.362306</td>\n",
       "      <td>0.144312</td>\n",
       "      <td>0.903535</td>\n",
       "      <td>Rain</td>\n",
       "      <td>-0.418186</td>\n",
       "      <td>1.014450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Winter</td>\n",
       "      <td>(-0.655, -0.253]</td>\n",
       "      <td>(0.0874, 0.412]</td>\n",
       "      <td>(0.838, 1.126]</td>\n",
       "      <td>(-0.649, -0.257]</td>\n",
       "      <td>(0.725, 1.071]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  avg_temperature  humidity  avg_wind_speed rain_or_not  \\\n",
       "0 2023-01-01        -0.346303 -0.479808        0.057716        Rain   \n",
       "1 2023-01-02         0.601659  0.253825       -0.415527        Rain   \n",
       "2 2023-01-03         0.350490 -0.195465        1.078158        Rain   \n",
       "3 2023-01-04         0.227672 -0.107915       -0.318667        Rain   \n",
       "4 2023-01-05        -0.362306  0.144312        0.903535        Rain   \n",
       "\n",
       "   cloud_cover  pressure  rain_or_not_binary  month  day_of_week  day_of_year  \\\n",
       "0    -1.027348 -0.281128                   1      1            6            1   \n",
       "1     1.528340  1.257899                   1      1            0            2   \n",
       "2    -1.353475  1.150926                   1      1            1            3   \n",
       "3     1.127882 -1.127123                   1      1            2            4   \n",
       "4    -0.418186  1.014450                   1      1            3            5   \n",
       "\n",
       "   season avg_temperature_bins     humidity_bins avg_wind_speed_bins  \\\n",
       "0  Winter     (-0.655, -0.253]  (-0.813, -0.303]    (-0.0421, 0.187]   \n",
       "1  Winter         (0.444, 0.8]   (0.0874, 0.412]      (-0.593, -0.3]   \n",
       "2  Winter       (0.171, 0.444]  (-0.303, 0.0874]      (0.838, 1.126]   \n",
       "3  Winter       (0.171, 0.444]  (-0.303, 0.0874]      (-0.593, -0.3]   \n",
       "4  Winter     (-0.655, -0.253]   (0.0874, 0.412]      (0.838, 1.126]   \n",
       "\n",
       "   cloud_cover_bins     pressure_bins  \n",
       "0  (-1.049, -0.649]  (-0.727, -0.244]  \n",
       "1    (1.337, 1.768]    (1.071, 1.326]  \n",
       "2  (-1.418, -1.049]    (1.071, 1.326]  \n",
       "3    (1.013, 1.337]  (-1.412, -1.072]  \n",
       "4  (-0.649, -0.257]    (0.725, 1.071]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking data types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date                    datetime64[ns]\n",
       "avg_temperature                float64\n",
       "humidity                       float64\n",
       "avg_wind_speed                 float64\n",
       "rain_or_not                     object\n",
       "cloud_cover                    float64\n",
       "pressure                       float64\n",
       "rain_or_not_binary               int64\n",
       "month                            int64\n",
       "day_of_week                      int64\n",
       "day_of_year                      int64\n",
       "season                          object\n",
       "avg_temperature_bins            object\n",
       "humidity_bins                   object\n",
       "avg_wind_speed_bins             object\n",
       "cloud_cover_bins                object\n",
       "pressure_bins                   object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-hot encoding the 'season' feature...\n",
      "\n",
      "2. Preparing features and target\n",
      "--------------------------------------------------\n",
      "\n",
      "Features to be used in modeling:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['avg_temperature',\n",
       " 'humidity',\n",
       " 'avg_wind_speed',\n",
       " 'cloud_cover',\n",
       " 'pressure',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'day_of_year',\n",
       " 'avg_temperature_bins',\n",
       " 'humidity_bins',\n",
       " 'avg_wind_speed_bins',\n",
       " 'cloud_cover_bins',\n",
       " 'pressure_bins',\n",
       " 'season_Fall',\n",
       " 'season_Spring',\n",
       " 'season_Summer',\n",
       " 'season_Winter']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (311, 17)\n",
      "Target vector shape: (311,)\n",
      "\n",
      "3. Splitting the data into training and testing sets\n",
      "--------------------------------------------------\n",
      "Training set shape: X_train: (248, 17), y_train: (248,)\n",
      "Testing set shape: X_test: (63, 17), y_test: (63,)\n",
      "\n",
      "4. Training and evaluating multiple models\n",
      "--------------------------------------------------\n",
      "\n",
      "Training and evaluating Logistic Regression...\n",
      "  Accuracy: 0.6667\n",
      "  Precision: 0.7021\n",
      "  Recall: 0.8250\n",
      "  F1 Score: 0.7586\n",
      "  ROC AUC: 0.7359\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.39      0.46        23\n",
      "           1       0.70      0.82      0.76        40\n",
      "\n",
      "    accuracy                           0.67        63\n",
      "   macro avg       0.63      0.61      0.61        63\n",
      "weighted avg       0.65      0.67      0.65        63\n",
      "\n",
      "\n",
      "Training and evaluating Decision Tree...\n",
      "  Accuracy: 0.6349\n",
      "  Precision: 0.6977\n",
      "  Recall: 0.7500\n",
      "  F1 Score: 0.7229\n",
      "  ROC AUC: 0.5924\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.43      0.47        23\n",
      "           1       0.70      0.75      0.72        40\n",
      "\n",
      "    accuracy                           0.63        63\n",
      "   macro avg       0.60      0.59      0.59        63\n",
      "weighted avg       0.63      0.63      0.63        63\n",
      "\n",
      "\n",
      "Training and evaluating Random Forest...\n",
      "  Accuracy: 0.6349\n",
      "  Precision: 0.6735\n",
      "  Recall: 0.8250\n",
      "  F1 Score: 0.7416\n",
      "  ROC AUC: 0.6516\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.30      0.38        23\n",
      "           1       0.67      0.82      0.74        40\n",
      "\n",
      "    accuracy                           0.63        63\n",
      "   macro avg       0.59      0.56      0.56        63\n",
      "weighted avg       0.61      0.63      0.61        63\n",
      "\n",
      "\n",
      "Training and evaluating Gradient Boosting...\n",
      "  Accuracy: 0.5873\n",
      "  Precision: 0.6591\n",
      "  Recall: 0.7250\n",
      "  F1 Score: 0.6905\n",
      "  ROC AUC: 0.6674\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.35      0.38        23\n",
      "           1       0.66      0.72      0.69        40\n",
      "\n",
      "    accuracy                           0.59        63\n",
      "   macro avg       0.54      0.54      0.54        63\n",
      "weighted avg       0.57      0.59      0.58        63\n",
      "\n",
      "\n",
      "Training and evaluating XGBoost...\n",
      "  Accuracy: 0.5873\n",
      "  Precision: 0.6458\n",
      "  Recall: 0.7750\n",
      "  F1 Score: 0.7045\n",
      "  ROC AUC: 0.6174\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.26      0.32        23\n",
      "           1       0.65      0.78      0.70        40\n",
      "\n",
      "    accuracy                           0.59        63\n",
      "   macro avg       0.52      0.52      0.51        63\n",
      "weighted avg       0.56      0.59      0.56        63\n",
      "\n",
      "\n",
      "Model Comparison Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.735870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>0.592391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.651630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.667391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.617391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy  precision  recall  f1_score   roc_auc\n",
       "Logistic Regression  0.666667   0.702128   0.825  0.758621  0.735870\n",
       "Decision Tree        0.634921   0.697674   0.750  0.722892  0.592391\n",
       "Random Forest        0.634921   0.673469   0.825  0.741573  0.651630\n",
       "Gradient Boosting    0.587302   0.659091   0.725  0.690476  0.667391\n",
       "XGBoost              0.587302   0.645833   0.775  0.704545  0.617391"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model based on ROC AUC: Logistic Regression\n",
      "\n",
      "5. Cross-validation of the best model\n",
      "--------------------------------------------------\n",
      "\n",
      "Cross-validation ROC AUC scores for Logistic Regression:\n",
      "[0.85326087 0.74886364 0.61136364 0.60423634 0.73690078]\n",
      "Mean ROC AUC: 0.7109\n",
      "Standard Deviation: 0.0935\n",
      "\n",
      "6. Feature Importance Analysis\n",
      "--------------------------------------------------\n",
      "\n",
      "Feature Coefficients:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>humidity</td>\n",
       "      <td>0.708052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>season_Winter</td>\n",
       "      <td>0.605357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_wind_speed</td>\n",
       "      <td>0.283179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pressure</td>\n",
       "      <td>0.181307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>season_Summer</td>\n",
       "      <td>0.143587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_temperature</td>\n",
       "      <td>0.074158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cloud_cover</td>\n",
       "      <td>0.066553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>day_of_week</td>\n",
       "      <td>0.051808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day_of_year</td>\n",
       "      <td>0.002750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>humidity_bins</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>avg_wind_speed_bins</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cloud_cover_bins</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pressure_bins</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>avg_temperature_bins</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>month</td>\n",
       "      <td>-0.073553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>season_Spring</td>\n",
       "      <td>-0.180141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>season_Fall</td>\n",
       "      <td>-0.370603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature  Coefficient\n",
       "1               humidity     0.708052\n",
       "16         season_Winter     0.605357\n",
       "2         avg_wind_speed     0.283179\n",
       "4               pressure     0.181307\n",
       "15         season_Summer     0.143587\n",
       "0        avg_temperature     0.074158\n",
       "3            cloud_cover     0.066553\n",
       "6            day_of_week     0.051808\n",
       "7            day_of_year     0.002750\n",
       "9          humidity_bins     0.000000\n",
       "10   avg_wind_speed_bins     0.000000\n",
       "11      cloud_cover_bins     0.000000\n",
       "12         pressure_bins     0.000000\n",
       "8   avg_temperature_bins     0.000000\n",
       "5                  month    -0.073553\n",
       "14         season_Spring    -0.180141\n",
       "13           season_Fall    -0.370603"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. Hyperparameter Tuning\n",
      "--------------------------------------------------\n",
      "\n",
      "Performing hyperparameter tuning for Logistic Regression...\n",
      "\n",
      "Best parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.1}\n",
      "Best cross-validation score: 0.6975\n",
      "\n",
      "Tuned Model Performance:\n",
      "  Accuracy: 0.6825\n",
      "  Precision: 0.7000\n",
      "  Recall: 0.8750\n",
      "  F1 Score: 0.7778\n",
      "  ROC AUC: 0.7109\n",
      "\n",
      "Classification Report for Tuned Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.35      0.44        23\n",
      "           1       0.70      0.88      0.78        40\n",
      "\n",
      "    accuracy                           0.68        63\n",
      "   macro avg       0.66      0.61      0.61        63\n",
      "weighted avg       0.67      0.68      0.66        63\n",
      "\n",
      "\n",
      "Training the final model on the full dataset...\n",
      "\n",
      "8. Generating predictions for the next 21 days\n",
      "--------------------------------------------------\n",
      "Last date in the dataset: 2023-11-07 00:00:00\n",
      "Future dates to predict: 2023-11-08 00:00:00 to 2023-11-28 00:00:00\n",
      "\n",
      "Simulating weather features for future predictions...\n",
      "Average avg_temperature for last 7 days: -0.58\n",
      "Average humidity for last 7 days: -0.85\n",
      "Average avg_wind_speed for last 7 days: -0.06\n",
      "Average cloud_cover for last 7 days: -0.17\n",
      "Average pressure for last 7 days: -0.48\n",
      "\n",
      "Predictions for the next 21 days:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rain_prediction</th>\n",
       "      <th>rain_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.403533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.486951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.347719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.443458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-11-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.422231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-11-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-11-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.482036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.384486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.345832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-11-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-11-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-11-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.403447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.377546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  rain_prediction  rain_probability\n",
       "0   2023-11-08                0          0.403533\n",
       "1   2023-11-09                0          0.433503\n",
       "2   2023-11-10                0          0.486951\n",
       "3   2023-11-11                0          0.451028\n",
       "4   2023-11-12                1          0.533671\n",
       "5   2023-11-13                0          0.347719\n",
       "6   2023-11-14                0          0.438432\n",
       "7   2023-11-15                0          0.443458\n",
       "8   2023-11-16                0          0.422231\n",
       "9   2023-11-17                0          0.487101\n",
       "10  2023-11-18                0          0.476304\n",
       "11  2023-11-19                0          0.482036\n",
       "12  2023-11-20                0          0.384486\n",
       "13  2023-11-21                0          0.345832\n",
       "14  2023-11-22                0          0.433033\n",
       "15  2023-11-23                0          0.410316\n",
       "16  2023-11-24                0          0.461289\n",
       "17  2023-11-25                0          0.466768\n",
       "18  2023-11-26                0          0.403447\n",
       "19  2023-11-27                0          0.437226\n",
       "20  2023-11-28                0          0.377546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9. Saving the final model\n",
      "--------------------------------------------------\n",
      "Model saved as 'rain_prediction_model.pkl'\n",
      "Feature list saved as 'model_features.txt'\n",
      "Future predictions saved as 'future_rain_predictions.csv'\n",
      "\n",
      "Model training, evaluation, and prediction completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Weather Forecasting Challenge - Model Training and Evaluation\n",
    "# Intellihack 5 Hackathon\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import warnings\n",
    "import re  # Add this line to import the 're' module\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Weather Forecasting Challenge - Model Training and Evaluation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Load the processed data\n",
    "print(\"\\n1. Loading the processed data\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Load the processed dataset\n",
    "df_processed = pd.read_csv('weather_data_processed.csv')\n",
    "df_processed['date'] = pd.to_datetime(df_processed['date'])\n",
    "\n",
    "print(f\"Loaded dataset shape: {df_processed.shape}\")\n",
    "display(df_processed.head())\n",
    "\n",
    "# Check if categorical features need encoding\n",
    "print(\"\\nChecking data types:\")\n",
    "display(df_processed.dtypes)\n",
    "\n",
    "# If 'season' is a string, one-hot encode it\n",
    "if df_processed['season'].dtype == 'object':\n",
    "    print(\"\\nOne-hot encoding the 'season' feature...\")\n",
    "    # Get dummies for season\n",
    "    season_dummies = pd.get_dummies(df_processed['season'], prefix='season')\n",
    "    df_processed = pd.concat([df_processed, season_dummies], axis=1)\n",
    "    df_processed.drop('season', axis=1, inplace=True)\n",
    "\n",
    "# 2. Prepare features and target\n",
    "print(\"\\n2. Preparing features and target\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Define features and target\n",
    "X = df_processed.drop(['date', 'rain_or_not', 'rain_or_not_binary'], axis=1)\n",
    "y = df_processed['rain_or_not_binary']\n",
    "\n",
    "# Store the binning and season information from X\n",
    "X_columns = X.columns\n",
    "# Get list of binning features\n",
    "binning_features = [col for col in X.columns if '_bins' in col]\n",
    "# Check if season is in dataframe\n",
    "if 'season_Fall' in X.columns:\n",
    "  seasonal_features = ['season_Fall', 'season_Spring', 'season_Summer', 'season_Winter']\n",
    "else:\n",
    "  seasonal_features = []\n",
    "\n",
    "# Convert interval columns to numeric in X\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        try:\n",
    "            # Attempt to convert to numeric, coercing errors to NaN\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "        except ValueError as e:\n",
    "            print(f\"Column '{col}' could not be converted to numeric: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error converting column '{col}': {e}\")\n",
    "\n",
    "# Fill NaN values with 0 or a more appropriate value\n",
    "X = X.fillna(0)  # Using 0 to avoid introducing new NaN values\n",
    "\n",
    "# Display feature names\n",
    "print(\"\\nFeatures to be used in modeling:\")\n",
    "display(X.columns.tolist())\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "\n",
    "# 3. Split the data\n",
    "print(\"\\n3. Splitting the data into training and testing sets\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set shape: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Testing set shape: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# 4. Model training and evaluation\n",
    "print(\"\\n4. Training and evaluating multiple models\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "model_predictions = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining and evaluating {name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Store predictions\n",
    "    model_predictions[name] = {\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob\n",
    "    }\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    # Store metrics\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  ROC AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['No Rain', 'Rain'],\n",
    "                yticklabels=['No Rain', 'Rain'])\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(f'confusion_matrix_{name.replace(\" \", \"_\").lower()}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Summarize model comparison\n",
    "print(\"\\nModel Comparison Summary:\")\n",
    "results_df = pd.DataFrame(results).T\n",
    "display(results_df)\n",
    "\n",
    "# Plot model comparison\n",
    "plt.figure(figsize=(14, 8))\n",
    "results_df.plot(kind='bar', figsize=(14, 8))\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Find the best model\n",
    "best_model_name = results_df['roc_auc'].idxmax()\n",
    "print(f\"\\nBest model based on ROC AUC: {best_model_name}\")\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# 5. Cross-validation of the best model\n",
    "print(\"\\n5. Cross-validation of the best model\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='roc_auc')\n",
    "print(f\"\\nCross-validation ROC AUC scores for {best_model_name}:\")\n",
    "print(cv_scores)\n",
    "print(f\"Mean ROC AUC: {cv_scores.mean():.4f}\")\n",
    "print(f\"Standard Deviation: {cv_scores.std():.4f}\")\n",
    "\n",
    "# 6. Feature importance analysis\n",
    "print(\"\\n6. Feature Importance Analysis\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get feature importances from the best model (if available)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Get feature importances\n",
    "    importances = best_model.feature_importances_\n",
    "    \n",
    "    # Create DataFrame for feature importances\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importances:\")\n",
    "    display(feature_importance_df)\n",
    "    \n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "    plt.title(f'Feature Importances from {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importances.png')\n",
    "    plt.close()\n",
    "elif best_model_name == 'Logistic Regression':\n",
    "    # For logistic regression, use coefficients\n",
    "    coefficients = best_model.coef_[0]\n",
    "    \n",
    "    # Create DataFrame for coefficients\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Coefficient': coefficients\n",
    "    }).sort_values(by='Coefficient', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Coefficients:\")\n",
    "    display(feature_importance_df)\n",
    "    \n",
    "    # Plot coefficients\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Coefficient', y='Feature', data=feature_importance_df)\n",
    "    plt.title(f'Feature Coefficients from {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_coefficients.png')\n",
    "    plt.close()\n",
    "\n",
    "# 7. Hyperparameter tuning\n",
    "print(\"\\n7. Hyperparameter Tuning\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Define parameter grids for each model type\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [None, 5, 10, 15, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Check if the best model has a parameter grid\n",
    "if best_model_name in param_grids:\n",
    "    print(f\"\\nPerforming hyperparameter tuning for {best_model_name}...\")\n",
    "    \n",
    "    # Get parameter grid for the best model\n",
    "    param_grid = param_grids[best_model_name]\n",
    "    \n",
    "    # Create a new instance of the best model\n",
    "    tuning_model = models[best_model_name]\n",
    "    \n",
    "    # Use RandomizedSearchCV for faster tuning\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=tuning_model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=10,  # Number of parameter settings to try\n",
    "        cv=5,\n",
    "        scoring='roc_auc',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Fit RandomizedSearchCV\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print the best parameters and score\n",
    "    print(f\"\\nBest parameters: {random_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {random_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Create the best model with optimized parameters\n",
    "    best_model = random_search.best_estimator_\n",
    "    \n",
    "    # Evaluate the tuned model\n",
    "    y_pred_tuned = best_model.predict(X_test)\n",
    "    y_prob_tuned = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics for the tuned model\n",
    "    accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "    precision_tuned = precision_score(y_test, y_pred_tuned)\n",
    "    recall_tuned = recall_score(y_test, y_pred_tuned)\n",
    "    f1_tuned = f1_score(y_test, y_pred_tuned)\n",
    "    roc_auc_tuned = roc_auc_score(y_test, y_prob_tuned)\n",
    "    \n",
    "    # Print metrics for the tuned model\n",
    "    print(\"\\nTuned Model Performance:\")\n",
    "    print(f\"  Accuracy: {accuracy_tuned:.4f}\")\n",
    "    print(f\"  Precision: {precision_tuned:.4f}\")\n",
    "    print(f\"  Recall: {recall_tuned:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_tuned:.4f}\")\n",
    "    print(f\"  ROC AUC: {roc_auc_tuned:.4f}\")\n",
    "    \n",
    "    # Print classification report for the tuned model\n",
    "    print(\"\\nClassification Report for Tuned Model:\")\n",
    "    print(classification_report(y_test, y_pred_tuned))\n",
    "    \n",
    "    # Plot confusion matrix for the tuned model\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm_tuned = confusion_matrix(y_test, y_pred_tuned)\n",
    "    sns.heatmap(cm_tuned, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['No Rain', 'Rain'],\n",
    "                yticklabels=['No Rain', 'Rain'])\n",
    "    plt.title(f'Confusion Matrix - Tuned {best_model_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(f'confusion_matrix_tuned_{best_model_name.replace(\" \", \"_\").lower()}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Train the final model on the full dataset\n",
    "    print(\"\\nTraining the final model on the full dataset...\")\n",
    "    best_model.fit(X, y)\n",
    "else:\n",
    "    print(f\"\\nHyperparameter grid not defined for {best_model_name}. Skipping tuning.\")\n",
    "    # Train the final model on the full dataset\n",
    "    print(\"Training the final model on the full dataset...\")\n",
    "    best_model.fit(X, y)\n",
    "\n",
    "# 8. Generate predictions for the next 21 days\n",
    "print(\"\\n8. Generating predictions for the next 21 days\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ... (previous code remains the same until future date generation)\n",
    "\n",
    "# Get the last date in the dataset\n",
    "last_date = df_processed['date'].max()\n",
    "print(f\"Last date in the dataset: {last_date}\")\n",
    "\n",
    "# Generate dates for the next 21 days\n",
    "future_dates = [last_date + timedelta(days=i+1) for i in range(21)]\n",
    "print(f\"Future dates to predict: {future_dates[0]} to {future_dates[-1]}\")\n",
    "\n",
    "# Create a DataFrame for future dates\n",
    "future_df = pd.DataFrame({'date': future_dates})\n",
    "\n",
    "# Extract features from dates\n",
    "future_df['month'] = future_df['date'].dt.month\n",
    "future_df['day_of_week'] = future_df['date'].dt.dayofweek\n",
    "future_df['day_of_year'] = future_df['date'].dt.dayofyear\n",
    "\n",
    "# Add season based on month\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "# Create season column and then one-hot encode it\n",
    "future_df['season'] = future_df['month'].apply(get_season)\n",
    "season_dummies = pd.get_dummies(future_df['season'], prefix='season')\n",
    "future_df = pd.concat([future_df, season_dummies], axis=1)\n",
    "future_df.drop('season', axis=1, inplace=True)\n",
    "\n",
    "# Simulate weather features for future days\n",
    "print(\"\\nSimulating weather features for future predictions...\")\n",
    "last_7_days = df_processed.sort_values('date').tail(7)\n",
    "\n",
    "# Calculate average values for numerical features\n",
    "weather_features = ['avg_temperature', 'humidity', 'avg_wind_speed', 'cloud_cover', 'pressure']\n",
    "for feature in weather_features:\n",
    "    if feature in df_processed.columns:\n",
    "        avg_value = last_7_days[feature].mean()\n",
    "        std_value = last_7_days[feature].std()\n",
    "        # Add some random variation\n",
    "        future_df[feature] = np.random.normal(avg_value, std_value/2, len(future_df))\n",
    "        print(f\"Average {feature} for last 7 days: {avg_value:.2f}\")\n",
    "\n",
    "# Add binning features (if they exist in original data)\n",
    "binning_features = [col for col in X.columns if '_bins' in col]\n",
    "for feature in binning_features:\n",
    "    future_df[feature] = 0  # Initialize with 0\n",
    "\n",
    "# Ensure all required columns are present\n",
    "for col in X.columns:\n",
    "    if col not in future_df.columns:\n",
    "        future_df[col] = 0\n",
    "\n",
    "# Make sure future_df has the same columns as X (in the same order)\n",
    "future_X = future_df[X.columns]\n",
    "\n",
    "# Make predictions\n",
    "future_preds_binary = best_model.predict(future_X)\n",
    "future_preds_prob = best_model.predict_proba(future_X)[:, 1]\n",
    "\n",
    "# Add predictions to the future DataFrame\n",
    "future_df['rain_prediction'] = future_preds_binary\n",
    "future_df['rain_probability'] = future_preds_prob\n",
    "\n",
    "# Display future predictions\n",
    "print(\"\\nPredictions for the next 21 days:\")\n",
    "prediction_results = future_df[['date', 'rain_prediction', 'rain_probability']].copy()\n",
    "prediction_results['date'] = prediction_results['date'].dt.strftime('%Y-%m-%d')\n",
    "display(prediction_results)\n",
    "\n",
    "# Rest of the code remains the same...\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(range(len(future_df)), future_df['rain_probability'], color=future_df['rain_prediction'].map({0: 'skyblue', 1: 'navy'}))\n",
    "plt.axhline(y=0.5, color='red', linestyle='--', label='50% Threshold')\n",
    "plt.xticks(range(len(future_df)), future_df['date'].dt.strftime('%Y-%m-%d'), rotation=45)\n",
    "plt.title('Rain Probability Forecast for the Next 21 Days')\n",
    "plt.ylabel('Probability of Rain')\n",
    "plt.xlabel('Date')\n",
    "plt.grid(True, axis='y')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('future_rain_forecast.png')\n",
    "plt.close()\n",
    "\n",
    "# 9. Save the final model\n",
    "print(\"\\n9. Saving the final model\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Save the model to disk\n",
    "pickle.dump(best_model, open('rain_prediction_model.pkl', 'wb'))\n",
    "print(\"Model saved as 'rain_prediction_model.pkl'\")\n",
    "\n",
    "# Save the feature list\n",
    "with open('model_features.txt', 'w') as f:\n",
    "    f.write('\\n'.join(X.columns))\n",
    "print(\"Feature list saved as 'model_features.txt'\")\n",
    "\n",
    "# Save future predictions\n",
    "future_df[['date', 'rain_prediction', 'rain_probability']].to_csv('future_rain_predictions.csv', index=False)\n",
    "print(\"Future predictions saved as 'future_rain_predictions.csv'\")\n",
    "\n",
    "print(\"\\nModel training, evaluation, and prediction completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
